{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EEG Signals-based Emotion Recognition\n",
        "## Methodology\n",
        "In recent weeks, I have explored more recent literature on this topic and encountered a newer [review paper](https://www.sciencedirect.com/science/article/pii/S0010482523009150?via%3Dihub). I observed that methods achieving the highest performance metrics (such as accuracy and precision) often incorporate either the spatial component of EEG signals or both spatial and temporal components. A common approach, following data acquisition and preprocessing, involves projecting the time-series EEG data onto brain images, then using model architectures that leverage both spatial and temporal features simultaneously. This approach inspired me to consider combining time-domain and frequency-domain information in the preprocessing stage by applying time-frequency domain analysis techniques.\n",
        "\n",
        "## Why Time-Frequency Domain Analysis?\n",
        "- **Non-Stationary Nature of EEG**: EEG signals often exhibit transient events and oscillatory behavior that standard time-domain or frequency-domain analyses alone may not capture.\n",
        "- **Comprehensive Representation**: Time-frequency methods provide a two-dimensional view of the signal, revealing how its frequency content evolves over time.\n",
        "- **Enhanced Feature Extraction**: This approach allows the deep learning model to learn features related to both temporal and spectral information, improving its performance in emotion recognition.\n",
        "\n",
        "## Choosing the Morlet Wavelet Transform\n",
        "### Characteristics of the Morlet Wavelet\n",
        "- **Complex Structure**: The Morlet wavelet is a Gaussian-modulated sinusoidal wave, which provides a good balance between time and frequency localization.\n",
        "- **High Frequency Resolution**: Ideal for analyzing signals with oscillatory behavior, such as brain waves, making it suitable for EEG analysis.\n",
        "- **Good for Dynamic Changes**: The Morlet wavelet is effective for detecting and analyzing changes in frequency over time, which aligns with the nature of emotional responses in EEG data.\n",
        "\n",
        "### Reasons for Choosing the Morlet Wavelet\n",
        "1. **Oscillatory Component Detection**: Emotions are often associated with different brain wave patterns (e.g., alpha, beta), which are effectively captured by the Morlet wavelet's oscillatory structure.\n",
        "2. **Time-Frequency Localization**: The Morlet wavelet provides a balance that allows for detailed analysis of how frequencies change over time, essential for mapping emotional states.\n",
        "3. **Proven Utility in EEG Analysis**: The Morlet wavelet is widely used in the field for time-frequency analysis due to its reliability in preserving the dynamic characteristics of non-stationary signals like EEG.\n",
        "\n",
        "## Conclusion\n",
        "I encountered a [paper](https://www.sciencedirect.com/science/article/pii/S1746809421002457) that employs a similar preprocessing approach to the one proposed here. Notably, they also used the SEED dataset, which provides a valuable point of comparison for evaluating methods and performance metrics in emotion recognition with EEG data. I welcome any suggestions or recommendations for further reading, particularly on  preprocessing techniques of the signals.\n",
        "## Implementation Note\n",
        "Most of algorithms are already implemented in the scientific Python module **Scipy (`scipy.signal`)** which can be used. I have some programming experience, to make amendements so it fits specific use cases as well.\n"
      ],
      "metadata": {
        "id": "dUbrpSwV7izu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwFRO1LKS_a_",
        "outputId": "08d96f22-915d-4830-ce1a-e71c2eccb4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from PyWavelets) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR4sVxjiZ_ev",
        "outputId": "bf8baf78-0709-40c1-f0c8-ef525cbbef93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear programming operations\n",
        "import pandas as pd # data manipulation and preprocessing\n",
        "import matplotlib.pyplot as plt # for plotting and data visualization\n",
        "import torch # pytorch for Deep Learning\n",
        "import torch.nn as nn # neural network module\n",
        "import torch.nn.functional as F # functional module\n",
        "import torch.optim as optim # model optimzer module\n",
        "import pywt # CWT\n",
        "from sklearn.decomposition import PCA #PCA\n",
        "import os\n",
        "from google.colab import drive # for mounting google drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEAP = [pd.read_pickle(f\"/content/drive/MyDrive/DEAP/data_preprocessed_python/s{i}.dat\") for i in range(1,33)]"
      ],
      "metadata": {
        "id": "MoFxQr37aECP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [DEAP[i]['data'] for i in range(0,32)]\n",
        "# data: 32 Subjects x 40 Trials (63 secs each with first 3 secs removed) x 40 Data rows (including 32 EEG channels) x 8064 (Timeseries data downsampled to 128 Hz amd EOG-filtered with bandpass filter of (4-45 Hz) average to common reference)\n",
        "labels = [DEAP[i]['labels'] for i in range(0,32)]\n",
        "# lables: 32 Subjects x 40 Trials x 4 Ratings (Valence,Arousal,Dominance,Liking)"
      ],
      "metadata": {
        "id": "b0dfOBlBbsVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = []\n",
        "\n",
        "for subject in data:\n",
        "    subject_processed = []\n",
        "    for trial in subject:\n",
        "        # Convert each trial (40x8064) to a Pandas DataFrame\n",
        "        df_trial = pd.DataFrame(trial)\n",
        "\n",
        "        # Drop the last 8 rows (We only need the 32 EEG channels)\n",
        "        df_trial_dropped = df_trial.iloc[:-8]\n",
        "\n",
        "        # Append the processed trial as a NumPy array\n",
        "        subject_processed.append(df_trial_dropped.to_numpy())\n",
        "\n",
        "    # Add processed subject to the list\n",
        "    processed_data.append(subject_processed)"
      ],
      "metadata": {
        "id": "BZ_taPiWc5jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data_flattened = [trial for subject in processed_data for trial in subject]\n",
        "labels_flattened = [trial for subject_labels in labels for trial in subject_labels]"
      ],
      "metadata": {
        "id": "TFVqvEV9gXXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(processed_data_flattened),\"\\n\", processed_data_flattened[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_W5CdREXMwL",
        "outputId": "b6950ee2-b3bc-44ca-f180-75731c09ec92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1280 \n",
            " (32, 8064)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all trials to create a single DataFrame\n",
        "eeg_signal_names = [\n",
        "    \"Fp1\", \"AF3\", \"F3\", \"F7\", \"FC5\", \"FC1\", \"C3\", \"T7\", \"CP5\", \"CP1\",\n",
        "    \"P3\", \"P7\", \"PO3\", \"O1\", \"Oz\", \"Pz\", \"Fp2\", \"AF4\", \"Fz\", \"F4\",\n",
        "    \"F8\", \"FC6\", \"FC2\", \"Cz\", \"C4\", \"T8\", \"CP6\", \"CP2\", \"P4\", \"P8\",\n",
        "    \"PO4\", \"O2\"\n",
        "]\n",
        "processed_data_df_list = [pd.DataFrame(trial) for trial in processed_data_flattened]\n",
        "for i in range(len(processed_data_df_list)):\n",
        "    processed_data_df_list[i] = processed_data_df_list[i].transpose()\n",
        "# Convert labels_flattened to a DataFrame\n",
        "labels_df = pd.DataFrame(labels_flattened, columns=['Valence', 'Arousal', 'Dominance', 'Liking'])"
      ],
      "metadata": {
        "id": "NpOpe7fTzHWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(processed_data_df_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4UJW8LW2oWQ",
        "outputId": "f63692d3-94b0-49a9-bbfe-4a062a3c6abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data_df_list[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N51dsDiWz41t",
        "outputId": "221a2442-c997-4a22-d189-17b1c3f4c6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8064, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRgCawj81D9F",
        "outputId": "61019890-986f-4029-99d3-827532679d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=16)\n",
        "for i in range(len(processed_data_df_list)):\n",
        "  processed_data_df_list[i] = pca.fit_transform(processed_data_df_list[i])\n",
        "data = np.array(processed_data_df_list)"
      ],
      "metadata": {
        "id": "P87WBIj32lKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "7VQx-hMj38eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3043c960-1937-4286-a868-a0f0790a5c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 8064, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scales = np.arange(1, 128)  # freq range\n",
        "sampling_frequency = 128  # 128 Hz for DEAP\n",
        "output_dir = \"scalograms\" # Save for later use\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Perform CWT and store scalograms\n",
        "for trial in range(0,1281):\n",
        "    trial_scalograms = []\n",
        "    for channel in range(0,16): # 16 PCs\n",
        "        signal = data[trial, :, channel] # Extract single trial-channel data\n",
        "        coef, freqs = pywt.cwt(signal, scales, 'cmor', sampling_period=1/sampling_frequency) # CWT\n",
        "        scalogram = np.abs(coef) ** 2\n",
        "        # Save the scalogram as a .npy file\n",
        "        filename = f\"scalogram_trial{trial}_channel{channel}.png\"\n",
        "        filepath = os.path.join(output_dir, filename)\n",
        "        # Save using a dedicated figure to ensure proper scaling\n",
        "        plt.figure(figsize=(12, 6))  # Adjust figure size for better resolution\n",
        "        plt.imshow(scalogram, extent=[0, 8064, freqs[-1], freqs[0]], aspect='auto', cmap='jet')\n",
        "        plt.axis('off')  # No axes\n",
        "        plt.tight_layout(pad=0)\n",
        "        plt.savefig(filepath, bbox_inches='tight', pad_inches=0)\n",
        "        plt.close()  # Close the figure to free memory\n",
        "        print(f\"Saved scalograms for Trial {trial + 1} and Channel {channel + 1}\")\n",
        "\n",
        "    # (Optional) Save trial-level scalograms if needed\n",
        "    # trial_filename = f\"scalograms_trial{trial}.npy\"\n",
        "    # trial_filepath = os.path.join(output_dir, trial_filename)\n",
        "    # np.save(trial_filepath, trial_scalograms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmQfdo4Oqc59",
        "outputId": "990bb8f1-c0a6-41ec-acd9-61a35a76d698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pywt/_cwt.py:117: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should takethe form cmorB-C where B and C are floats representing the bandwidth frequency and center frequency, respectively (example: cmor1.5-1.0).\n",
            "  wavelet = DiscreteContinuousWavelet(wavelet)\n"
          ]
        }
      ]
    }
  ]
}